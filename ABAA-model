{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1uDEazA4cv9j7RAe51AsZ_KxEce0PJrmZ","authorship_tag":"ABX9TyPVAbaogZ3doi7d6lJugAUB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"caB2WJH_CbA6","executionInfo":{"status":"ok","timestamp":1728067915605,"user_tz":360,"elapsed":11791,"user":{"displayName":"Monserrat Vázquez Hernández","userId":"12458819110641506711"}},"outputId":"bb290ce5-8241-4eda-c67c-6732a0068051"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Github/ABAA-model/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BlLHGTOrCxbu","executionInfo":{"status":"ok","timestamp":1728067917097,"user_tz":360,"elapsed":187,"user":{"displayName":"Monserrat Vázquez Hernández","userId":"12458819110641506711"}},"outputId":"73ef589c-85d1-45d9-fe18-609986b56007"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Github/ABAA-model\n"]}]},{"cell_type":"code","source":["pip install pyss3"],"metadata":{"id":"cYli3Ok7C98D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728067927847,"user_tz":360,"elapsed":9817,"user":{"displayName":"Monserrat Vázquez Hernández","userId":"12458819110641506711"}},"outputId":"2d55501b-84df-414c-ce07-071e486b45ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyss3 in /usr/local/lib/python3.10/dist-packages (0.6.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pyss3) (1.16.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from pyss3) (3.0.11)\n","Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.10/dist-packages (from scikit-learn[alldeps]>=0.20->pyss3) (1.5.2)\n","Requirement already satisfied: tqdm>=4.8.4 in /usr/local/lib/python3.10/dist-packages (from pyss3) (4.66.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pyss3) (3.7.1)\n","Requirement already satisfied: iterative-stratification in /usr/local/lib/python3.10/dist-packages (from pyss3) (0.1.7)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->scikit-learn[alldeps]>=0.20->pyss3) (1.26.4)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->scikit-learn[alldeps]>=0.20->pyss3) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->scikit-learn[alldeps]>=0.20->pyss3) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->scikit-learn[alldeps]>=0.20->pyss3) (3.5.0)\n","\u001b[33mWARNING: scikit-learn 1.5.2 does not provide the extra 'alldeps'\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyss3) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyss3) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyss3) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyss3) (1.4.7)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyss3) (24.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyss3) (10.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyss3) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyss3) (2.8.2)\n"]}]},{"cell_type":"markdown","source":["Libraries\n","\n","---\n","\n"],"metadata":{"id":"wBPfAiAcGn0O"}},{"cell_type":"code","source":["import statistics\n","from pyss3 import SS3\n","from pyss3.util import Dataset, Evaluation, span\n","\n","from numpy import dot\n","import numpy as np\n","import math\n","from numpy.linalg import norm\n","from scipy.spatial import distance\n","from scipy.special import logsumexp\n","from pandas import DataFrame\n","\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","\n","from gensim.models import Word2Vec\n","from gensim.scripts.glove2word2vec import glove2word2vec\n","from gensim.models import KeyedVectors"],"metadata":{"id":"4lctKzQ1GNKE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728071984041,"user_tz":360,"elapsed":165,"user":{"displayName":"Monserrat Vázquez Hernández","userId":"12458819110641506711"}},"outputId":"ec2a2ecc-5077-40a1-ce00-808d1c36b517"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["Methods\n","\n","---\n","\n"],"metadata":{"id":"ErsUwnVJIqdw"}},{"cell_type":"code","source":["#Classes\n","class Category:\n","  def __init__(self,category):\n","        self.category = category\n","        self.entity = \"\"\n","        self.aspect = \"\"\n","        self.reviews = [] #Opinions by category\n","        #Positive sentiment (reviews, vocabulary, vector)\n","        self.positive= Polaridad(\"positive\")\n","        #Negative sentiment (reviews, vocabulary, vector)\n","        self.negative = Polaridad(\"negative\")\n","        #Neutral sentiment(reviews, vocabulario, vector)\n","        self.neutral = Polaridad(\"neutral\")\n","\n","class Polaridad:\n","  def __init__(self,polarity_):\n","    self.polarity = polarity_\n","    self.reviews = []\n","    self.vocabulario = []\n","    self.vector = []\n","    self.mean = 0\n","    self.dev_std = 0\n","    self.umbral = 0\n","    self.diccionario_gv = dict() #Global values\n","\n","class Review:\n","  def __init__(self,review):\n","    self.review = review\n","    self.review_clean = ''\n","    self.polarity = ''\n","    self.vector_category = []\n","\n","class PCategory:\n","  def __init__(self, category):\n","    self.category = category\n","    self.Reviews = []\n","    self.accuracy = 0\n","    self.sim_neg = 0\n","    self.instance_neg = 0\n","    self.sim_pos = 0\n","    self.instance_pos = 0\n","    self.pr_pos = 0\n","    self.pr_neg = 0\n","\n","\n","class PReview:\n","  def __init__(self, review_, no_review_, polarity_):\n","    self.no_review_ = no_review_\n","    self.review = review_\n","    self.polarity = polarity_\n","    self.prob_neg = 0\n","    self.prob_pos = 0\n","    self.prob_neu = 0\n","    self.res_clasification = \"\"\n","    self.advexample = 0\n","\n","def CleanReview(review):\n","    ST = stopwords.words('english') #stop words\n","\n","    AuxReview = review.lower().replace(\"\\n\",\"\").replace(',',' ').replace('!',' ').replace(':',' ').replace('(',' ').replace(')',' ').replace('.',' ').replace('$t$s',' ').replace('$t$','').replace('\"',' ').replace('?',' ').replace('¿',' ').replace('!',' ').replace('¡',' ').replace('(…)',' ').replace('“”',' ').replace('″',' ').replace(';',' ').replace('-',' ').replace('//',' ')\n","    AuxReview = AuxReview.replace('<',' ').replace('+',' ').replace('>',' ').replace('”',' ').replace('“',' ').replace('”',' ').replace('//',' ').replace('…',' ').replace('’',' ').replace('º',' ').replace('‘',' ')\n","    AuxReview = AuxReview.replace('[',' ').replace(']',' ').replace('%',' ').replace(\"/\",\" \").replace(\"d´\",\"d\")\n","    AuxReview = AuxReview.replace('  ',' ').replace('€','').replace('0','').replace('1','').replace('2','').replace('3','').replace(\"l'o\",\"o\").replace('4','').replace('5','').replace('6','').replace('7','').replace('8','').replace('9','')\n","    AuxReview = AuxReview.replace('á','a').replace('é','e').replace('í','i').replace('ó','o').replace('ú','u').replace(\"*\",\" \").replace(\"-\",\" \")\n","\n","    #Get tokens from review\n","    tokens = AuxReview.split(' ')\n","\n","    #Remove stopwords\n","    clean_tokens = tokens[:]\n","    for token in tokens:\n","        if token in ST:\n","            clean_tokens.remove(token)\n","\n","    clean_review = \"\"\n","    for token in clean_tokens:\n","        clean_review += token + ' '\n","\n","    return clean_review.replace(\"  \",\" \")\n","\n","def CleanDocs(documentos):\n","    clean_Docs = []\n","    for doc in documentos:\n","        clean_Docs.append(CleanReview(doc))\n","\n","    return clean_Docs\n","\n","def cosine_distance(u,v):\n","    # print(u, v)\n","    # \"\"\" Returns the cosine of the angle between vectors v and u. This is equal to uv / |u||v|. \"\"\"\n","  return dot(u,v)/(logsumexp(norm(u)*norm(v))) if not (len(u) == 0 or len(v) == 0) else 0\n","\n","    # return distance.cosine(u, v\n","    # return np.dot(u, v) / (math.sqrt(np.dot(u,u) * math.sqrt(np.dot(v,v))))"],"metadata":{"id":"edCUxhe2IwOY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def input_data():\n","  # As local model\n","  # We define sentiment lexicons using de SS3 model\n","  # SS3 Model https://github.com/sergioburdisso/pyss3\n","  # The SS3 model, define a lexicon for each sentiment polarity according to the opinions on training dataset\n","\n","  clf = SS3()\n","\n","  # #-------------------------------------------------------------------------\n","  #Training opinions\n","  opinion_train = open('./Files/Laptop_dataset/LAPTOP_TRAIN_ABAA.reviews.gold','r', encoding='utf-8')\n","  x_train = [opinion.replace(\"\\n\",\"\") for opinion in opinion_train]\n","  opinion_train.close()\n","\n","  #Aspects by opinion in training dataset\n","  aspect_train = open('./Files/Laptop_dataset/LAPTOP_TRAIN_ABAA.aspects.gold','r', encoding='utf-8')\n","  a_train = [aspect.replace(\"\\n\",\"\") for aspect in aspect_train]\n","  aspect_train.close()\n","\n","  #Polarity-sentiment by aspect in training dataset\n","  polarities_train = open('./Files/Laptop_dataset/LAPTOP_TRAIN_ABAA.polarities.gold','r', encoding='utf-8')\n","  p_train = [polarity.replace(\"\\n\",\"\") for polarity in polarities_train]\n","  polarities_train.close()\n","\n","  # x_train= CleanDocs(x_train)\n","\n","  #--------------------------------------------------------------------------\n","\n","\n","  #------------------------------------------------------------------------\n","  #Test opinions\n","  opinion_test = open('./Files/Laptop_dataset/LAPTOP_TEST_ABAA.reviews.gold','r', encoding='utf-8')\n","  x_test = [opinion.replace(\"\\n\",\"\") for opinion in opinion_test]\n","  opinion_test.close()\n","\n","  #Aspects by opinion in test dataset\n","  aspect_test = open('./Files/Laptop_dataset/LAPTOP_TEST_ABAA.aspects.gold','r', encoding='utf-8')\n","  a_test = [aspect.replace(\"\\n\",\"\") for aspect in aspect_test]\n","  aspect_test.close()\n","\n","  #Polarity-sentiment by aspect in training dataset\n","  polarities_test = open('./Files/Laptop_dataset/LAPTOP_TEST_ABAA.polarities.gold','r', encoding='utf-8')\n","  p_test = [polarity.replace(\"\\n\",\"\") for polarity in polarities_test]\n","  polarities_test.close()\n","\n","  # x_test= CleanDocs(x_test)\n","  # #---------------------------------------------------------------------------\n","\n","  vocabulary_polarities_train = []\n","\n","\n","  if len(x_train) > 0:\n","    clf.train(x_train, p_train)\n","    flag_category_train = 1\n","    s_vals=[0.2 , 0.32, 0.44, 0.56, 0.68, 0.8]\n","    l_vals=[0.1 , 0.48, 0.86, 1.24, 1.62, 2]\n","    p_vals=[1.75, 1.95, 2.15, 2.35, 2.55, 2.75]\n","    best_s, best_l, best_p, _ = Evaluation.grid_search(clf,x_test, p_test, s=s_vals,l=l_vals,p=p_vals)\n","\n","    clf.set_hyperparameters(best_s, best_s, best_p, 0.0)\n","    clf.train(x_train, p_train)\n","\n","    polarities = clf.get_categories()\n","\n","\n","    ctr = 0\n","    beta = 0.4\n","\n","    #Sentiment lexicons\n","    negative_lexicon = []\n","    positive_lexicon = []\n","    neutral_lexicon = []\n","\n","    for polarity in polarities:\n","      vocab_ss3 = clf.__get_category_vocab__(ctr)\n","\n","      #File with lexicon\n","      freqFile= open(polarity + '.txt','w', encoding='utf-8')\n","      value_terms = []\n","      for item in vocab_ss3:\n","        if len(item[0]) >3 and item[4] >= beta:\n","          value_terms.append(item[0])\n","          freqFile.write(item[0] + ' ' + str(item[4]) + '\\n')\n","      freqFile.close()\n","\n","      if polarity == 'negative':\n","        negative_lexicon = value_terms\n","      elif polarity == 'neutral':\n","        neutral_lexicon = value_terms\n","      else:\n","        positive_lexicon = value_terms\n","\n","      ctr += 1\n","\n","\n","  # Output\n","  # 1. negative_lexicon = negative sentiment lexicon based on train test\n","  # 2. positive_lexicon = positive sentiment lexicon based on train test\n","  # 3. neutral_lexicon = neutral sentiment lexicon based on train test\n","  # 4. x_train = opinions in train set\n","  # 5. a_train = aspect by opinion in train set\n","  # 6. p_train = sentiment/polarity by opinion in train set\n","  # 7. x_test = opinions in test set\n","  # 8. a_test = aspect by opinion in train set\n","  # 9. p_test = sentiment/polarity by opinion in train set\n","\n","  return negative_lexicon, positive_lexicon, neutral_lexicon, x_train, a_train, p_train, x_test, a_test, p_test"],"metadata":{"id":"nKePfn_5FwTo","executionInfo":{"status":"ok","timestamp":1728069639799,"user_tz":360,"elapsed":222,"user":{"displayName":"Monserrat Vázquez Hernández","userId":"12458819110641506711"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"795af775-d341-497a-8df5-c3e20c09f2b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"markdown","source":["GloVe: Embeddings Twitter\n","\n","\n","---"],"metadata":{"id":"etCF3gZq_NnB"}},{"cell_type":"code","source":["\"\"\"Twitter\"\"\"\n","word2vec_output_file = './Files/glove.twitter.27B.200d.txt.word2vec'\n","model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n","embedding_size = 200"],"metadata":{"id":"7zUEm5aR_Nz9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Adversarial Examples\n","---"],"metadata":{"id":"QEEjb7VIAmUc"}},{"cell_type":"markdown","source":["Class and libreries\n","\n","---"],"metadata":{"id":"oFiqPcslAqRy"}},{"cell_type":"code","source":["pip install PyMultiDictionary"],"metadata":{"id":"uWw3ek0eA325"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Libraries for synonym information\n","import requests\n","import operator\n","import nltk\n","nltk.download('wordnet')\n","nltk.download('omw')\n","nltk.download('omw-1.4')\n","import random\n","from nltk.corpus import wordnet\n","# nltk.download('all')\n","\n","from PyMultiDictionary import MultiDictionary\n","#------------------------------------------\n","\n","#Clases\n","class TSinonimos:\n","  def __init__(self,termino, sinonimo):\n","    self.termino_ = termino\n","    self.sinonimo_ = sinonimo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oBEQmPiOAlbn","executionInfo":{"status":"ok","timestamp":1728071673434,"user_tz":360,"elapsed":914,"user":{"displayName":"Monserrat Vázquez Hernández","userId":"12458819110641506711"}},"outputId":"7aca3d59-129a-4e91-a26f-0508679cb37f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw to /root/nltk_data...\n","[nltk_data]   Package omw is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"]}]},{"cell_type":"code","source":["def dictionary_synomym(termino):\n","  #English\n","  sinonimos = dict()\n","  if termino in model:\n","    for syn in wordnet.synsets(termino):\n","      # print(syn.lemma_names())\n","      for name in syn.lemma_names():\n","        if name in model and name != termino:\n","          # aleatory\n","          # print(name)\n","          # print(model[termino])\n","          # print(cosine_distance(model[termino],model[name]))\n","          # cosine = cosine_distance(model[termino],model[name])\n","\n","          if cosine_distance(model[termino],model[name]) > 0:\n","            sinonimos[name] =  cosine_distance(model[termino],model[name])\n","\n","    if len(sinonimos) > 0:\n","      # Instrucción para tener el máximo valor de un diccionario\n","      # key, value = random.choice(list(sinonimos.items()))\n","      # return key\n","\n","      # Instrucción para tener el máximo valor de un diccionario\n","      max_key = max(sinonimos, key = sinonimos.get)\n","      return max_key\n","    else:\n","      return termino\n","  else:\n","    return termino"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hgr7a2yoGYEc","executionInfo":{"status":"ok","timestamp":1728075213997,"user_tz":360,"elapsed":251,"user":{"displayName":"Monserrat Vázquez Hernández","userId":"12458819110641506711"}},"outputId":"c53e2c75-e658-4630-e1af-74839fe57732"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"code","source":["def GetSynonym(term,LSinonimos):\n","  for term_ in LSinonimos:\n","    if term == term_.termino_:\n","      return term_.sinonimo_"],"metadata":{"id":"jLY6yJVBHA9e","executionInfo":{"status":"ok","timestamp":1728075195353,"user_tz":360,"elapsed":177,"user":{"displayName":"Monserrat Vázquez Hernández","userId":"12458819110641506711"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4029456e-0174-47bf-d3aa-c93947e9e4aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"code","source":["def Sinonyms(diccionario_gv):\n","  from collections import OrderedDict\n","\n","  TSinonimos_ = []\n","  noperturbado_ = 0\n","  perturbado_ = 0\n","\n","  for index, key in enumerate(OrderedDict(sorted(diccionario_gv.items(), key=lambda x: x[1], reverse=True))):\n","    # print(index, key, diccionario_gv[key],DiccionarioSinonimos(key))\n","    sinonimo_ = dictionary_synomym(key)\n","    if sinonimo_.replace(\" \",\"\") == key:\n","      noperturbado_ += 1\n","    else:\n","      perturbado_ += 1\n","\n","    TSinonimos_.append(TSinonimos(key,dictionary_synomym(key)))\n","\n","  # print(TSinonimos_)\n","  # print(\"Perturbados_ \",perturbado_)\n","  # print(\"NO  Perturbados_ \",noperturbado_)\n","  return TSinonimos_"],"metadata":{"id":"Jd_tYPOTGnM6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def VectorCategory(category):\n","  terms_ = category.split(\"#\")\n","  CVector_ = []\n","  no_terms = 0\n","\n","  for term in terms_:\n","    for iterm in term.split(\"_\"):\n","      # print(iterm)\n","      if iterm.lower() in model:\n","        if no_terms == 0:\n","          CVector_ = model[iterm.lower()]\n","        else:\n","          CVector_ = np.asarray(CVector_ + model[iterm.lower()])\n","\n","        no_terms += 1\n","\n","  #Vector único promedio\n","  CVector = np.asarray([n * (1/no_terms) for n in CVector_])\n","  # print(\"tÉRMINOS: \" + str(contador))\n","  return CVector"],"metadata":{"id":"eGuO7kqIHElL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1728075174167,"user_tz":360,"elapsed":222,"user":{"displayName":"Monserrat Vázquez Hernández","userId":"12458819110641506711"}},"outputId":"ae5abcfb-c51d-40a1-df16-0441e7cd99a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n","  and should_run_async(code)\n"]}]},{"cell_type":"code","source":["def VectorAspect(aspect_):\n","\n","  terms_ = CleanReview(aspect_).split()\n","  AVector_ = []\n","  no_terms = 0\n","  # print(terms_)\n","  for term in terms_:\n","    if term in model:\n","      if no_terms == 0:\n","        AVector_ = model[term]\n","      else:\n","        AVector_ = np.asarray(AVector_ + model[term])\n","\n","      no_terms += 1\n","\n","  #Vector único promedio\n","  return np.asarray([n * (1/no_terms) for n in AVector_])"],"metadata":{"id":"HqHUKZ-UHRNL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def VectorOpinion(input_):\n","  # instancia = CleanReview(input_)\n","  IVector_ = []\n","  no_terms = 0\n","  for term in input_.split():\n","      if term in model:\n","        if no_terms == 0:\n","          IVector_ = model[term]\n","        else:\n","          IVector_ = np.asarray(IVector_ + model[term])\n","\n","        no_terms += 1\n","\n","  IVector_ = np.asarray([n * (1/no_terms) for n in IVector_])\n","  return IVector_"],"metadata":{"id":"Smpg_UO5HU0B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def AdvExample_synonym_abaa(opinion_, sentiment_lexicon, aspect_, b_):\n","\n","  no_terms_modified_ = 0\n","  terms_modified_ = 0\n","  advexample_ = \"\"\n","  synonym_ = \"\"\n","  AVector_ = VectorAspect(aspect_)\n","  terms_aspect_ = aspect_.split()\n","  # terms_aspect_ = CleanReview(aspect_).split()\n","\n","  # print(instancia)\n","  # print(aspect_)\n","  # print(terms_aspect_)\n","  # print(b_)\n","\n","  for term in opinion_.split():\n","    if term in sentiment_lexicon and term not in terms_aspect_ and (cosine_distance(model[term],AVector_) if term in model else 0)  >= b_:\n","      synonym_ = dictionary_synomym(term)\n","      #Filtered terms are replaced by their closest semantic similarity synonym\n","      # print(term, \"-\", synonym_)\n","      if synonym_.replace(\" \",\"\") == term:\n","        advexample_ += term + \" \"\n","        no_terms_modified_ += 1\n","      else:\n","        advexample_ += synonym_ + \" \"\n","        terms_modified_ += 1\n","    else:\n","      advexample_ += term + \" \"\n","      no_terms_modified_ += 1\n","\n","\n","\n","  # print(opinion_)\n","  # print(advexample_)\n","  # print(len(opinion_.split()))\n","  # print(terms_modified_)\n","  # print(cosine_distance(VectorOpinion(opinion_),VectorOpinion(advexample_)))\n","  # print(aspect_)\n","  # print(\"----------------------------------\")\n","  return advexample_, terms_modified_, no_terms_modified_, cosine_distance(VectorOpinion(opinion_),VectorOpinion(advexample_)) if terms_modified_ > 0 else 1"],"metadata":{"id":"m_AGLk5KG66o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def AdvExample_delete_abaa(opinion_, sentiment_lexicon, aspect_, b_):\n","  no_terms_modified_ = 0\n","  terms_modified_ = 0\n","  advexample_ = \"\"\n","  synonym_ = \"\"\n","  AVector_ = VectorAspect(aspect_)\n","  terms_aspect_ = aspect_.split()\n","  # terms_aspect_ = CleanReview(aspect_).split()\n","\n","  # print(instancia)\n","  # print(aspect_)\n","  # print(terms_aspect_)\n","  # print(b_)\n","\n","  for term in opinion_.split():\n","    if term in sentiment_lexicon and term not in terms_aspect_ and (cosine_distance(model[term],AVector_) if term in model else 0)  >= b_:\n","        terms_modified_ += 1\n","        advexample_ += \" \"\n","    else:\n","      advexample_ += term + \" \"\n","      no_terms_modified_ += 1\n","\n","  # print(opinion_)\n","  # print(advexample_)\n","  # print(len(opinion_.split()))\n","  # print(terms_modified_)\n","  # print(cosine_distance(VectorOpinion(opinion_),VectorOpinion(advexample_)))\n","  # print(aspect_)\n","  # print(\"----------------------------------\")\n","  return advexample_, terms_modified_, no_terms_modified_, cosine_distance(VectorOpinion(opinion_),VectorOpinion(advexample_)) if terms_modified_ > 0 else 1"],"metadata":{"id":"0kVtD4UoHwwa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def AdvExample_delete(opinion_, sentiment_lexicon, aspect_, b_):\n","  no_terms_modified_ = 0\n","  terms_modified_ = 0\n","  advexample_ = \"\"\n","  synonym_ = \"\"\n","  AVector_ = VectorAspect(aspect_)\n","  terms_aspect_ = aspect_.split()\n","  # terms_aspect_ = CleanReview(aspect_).split()\n","\n","  # print(instancia)\n","  # print(aspect_)\n","  # print(terms_aspect_)\n","  # print(b_)\n","\n","  for term in opinion_.split():\n","    if term in sentiment_lexicon:\n","        terms_modified_ += 1\n","        advexample_ += \" \"\n","    else:\n","      advexample_ += term + \" \"\n","      no_terms_modified_ += 1\n","\n","\n","\n","  # print(opinion_)\n","  # print(advexample_)\n","  # print(len(opinion_.split()))\n","  # print(terms_modified_)\n","  # print(cosine_distance(VectorOpinion(opinion_),VectorOpinion(advexample_)))\n","  # print(aspect_)\n","  # print(\"----------------------------------\")\n","  return advexample_, terms_modified_, no_terms_modified_, cosine_distance(VectorOpinion(opinion_),VectorOpinion(advexample_)) if terms_modified_ > 0 else 1"],"metadata":{"id":"mS2Kg9OZHurI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def AdvExample_synonym(opinion_, sentiment_lexicon, aspect_, b_):\n","\n","  no_terms_modified_ = 0\n","  terms_modified_ = 0\n","  advexample_ = \"\"\n","  synonym_ = \"\"\n","  AVector_ = VectorAspect(aspect_)\n","  terms_aspect_ = aspect_.split()\n","  # terms_aspect_ = CleanReview(aspect_).split()\n","\n","  # print(instancia)\n","  # print(aspect_)\n","  # print(terms_aspect_)\n","  # print(b_)\n","\n","  for term in opinion_.split():\n","    if term in sentiment_lexicon:\n","      synonym_ = dictionary_synomym(term)\n","      #Filtered terms are replaced by their closest semantic similarity synonym\n","      # print(term, \"-\", synonym_)\n","      if synonym_.replace(\" \",\"\") == term:\n","        advexample_ += term + \" \"\n","        no_terms_modified_ += 1\n","      else:\n","        advexample_ += synonym_ + \" \"\n","        terms_modified_ += 1\n","    else:\n","      advexample_ += term + \" \"\n","      no_terms_modified_ += 1\n","\n","\n","\n","  # print(opinion_)\n","  # print(advexample_)\n","  # print(len(opinion_.split()))\n","  # print(terms_modified_)\n","  # print(cosine_distance(VectorOpinion(opinion_),VectorOpinion(advexample_)))\n","  # print(aspect_)\n","  # print(\"----------------------------------\")\n","  return advexample_, terms_modified_, no_terms_modified_, cosine_distance(VectorOpinion(opinion_),VectorOpinion(advexample_)) if terms_modified_ > 0 else 1"],"metadata":{"id":"OsXsIGcGTU2K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from numpy.lib.index_tricks import index_exp\n","import random\n","\n","def AdversarialExamples(negative_lexicon, positive_lexicon, neutral_lexicon, x_train, a_train, p_train, b_):\n","\n","  #-----------------------------------------------------------------------\n","  pr_acumulado = 0 #Perturbation ratio\n","  suma_similitud_ = 0 #semantic similarity\n","  advexamples_  = 0 #No. adversarial examples\n","  x_adversarial_ABAA = [] #Dataset after modifications\n","  x_adversarial_DL = []\n","  x_original_opinions = []\n","  x_aspects_ = []\n","  x_polaridad_ = []\n","  opinion_ = \"\"\n","\n","\n","  for index in range(len(x_test)):\n","    opinion_ = CleanReview(x_test[index])\n","    polaridad_ = p_test[index]\n","    aspect_ = a_test[index]\n","\n","    # print(opinion_)\n","    # print(polaridad_)\n","    # print(aspect_)\n","    lexicon_polaridad_ = negative_lexicon if polaridad_ == 'negative' else positive_lexicon if polaridad_ == 'positive' else neutral_lexicon\n","\n","    term_modified_ = 0\n","    no_term_modified_ = 0\n","    similarity_ = 0\n","\n","    # word-replace by synonym\n","    advexample_, term_modified_, no_term_modified_, similarity_ = AdvExample_synonym_abaa(opinion_, lexicon_polaridad_, aspect_, b_)\n","\n","    if term_modified_ > 0:\n","      x_original_opinions.append(opinion_)\n","      x_adversarial_ABAA.append(advexample_)\n","      x_aspects_.append(aspect_)\n","      x_polaridad_.append(polaridad_)\n","\n","    x_train[index] = advexample_\n","\n","    # ----------------------------------------------\n","    # Acumulado para métricas de evalución\n","    pr_acumulado = pr_acumulado + (term_modified_ * 100) / len(opinion_.split()) if term_modified_ > 0 else pr_acumulado\n","    suma_similitud_ = suma_similitud_ + similarity_ if term_modified_ > 0 else suma_similitud_\n","    advexamples_ = advexamples_ + 1 if term_modified_ > 0 else advexamples_\n","\n","  # Return\n","  # 1. Initial dataset\n","  # 2. Adversarial Examples generated\n","  # 3. Final dataset (initial dataset + adversarial examples)\n","  # 4. Aspect of adversarial example\n","  # 5. Polarity of adversarial example\n","  # 6. Perturbation ratio (promedio)\n","  # 7. No. Adversarial examples (total)\n","  # 8. % Dataset modified\n","\n","  return x_original_opinions, x_adversarial_ABAA, x_train, x_aspects_, x_polaridad_, round(suma_similitud_/advexamples_,3) if advexamples_ > 0 else 0, round(pr_acumulado / advexamples_,3) if advexamples_ > 0 else 0 , advexamples_, round((advexamples_*100)/len(x_test),3)"],"metadata":{"id":"qF4bSTrxG2KC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["negative_lexicon, positive_lexicon, neutral_lexicon, x_train, a_train, p_train, x_test, a_test, p_test = input_data()\n","\n","print(\"Negative lexicon: \", negative_lexicon)\n","print(\"Positive lexicon: \", positive_lexicon)\n","print(\"Neutral lexicon: \", neutral_lexicon)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dxRWR3cJMPf5","executionInfo":{"status":"ok","timestamp":1728072120467,"user_tz":360,"elapsed":988,"user":{"displayName":"Monserrat Vázquez Hernández","userId":"12458819110641506711"}},"outputId":"af5183a5-3a92-4fa1-91fd-3a574e531817"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Training on 'positive': 100%|██████████| 3/3 [00:00<00:00, 12.34it/s]\n","Grid search: 100%|██████████| 216/216 [00:00<00:00, 71381.16it/s]\n","Training on 'positive': 100%|██████████| 3/3 [00:00<00:00, 11.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Negative lexicon:  ['then', 'months', 'coming', 'cords', 'slow', 'sound', 'supply', 'front', 'within', 'buttons', 'update', 'warrenty', 'change', 'headphones', 'left', 'tech', 'short', 'being', 'isnt', 'keep', 'wouldnt', 'less', 'wont', 'wish', 'board', 'bios', 'mention', 'unable', 'designed', 'quits', 'setup', 'second', 'updated', 'else', 'nothing', 'replace', 'went', 'wheel', 'company', 'network', 'volume', 'anytime', 'horrible', 'held', 'messy', 'away', 'edges', 'twice', 'direction', 'plugged', 'froze', 'expected', 'shut', 'half', 'numerous', 'loud', 'paint', 'awful', 'either', 'break', 'thus', 'button', 'started', 'poorly', 'continued', 'useless', 'installation', 'usual', 'hated', 'physical', 'bulk', 'worse', 'nnbrrnd', 'detect', 'typed', 'models', 'holding', 'crashed', 'headphone', 'supposed', 'freaking', 'terrible', 'viruses', 'speaker', 'died', 'stuck', 'wasnt', 'control', 'noise']\n","Positive lexicon:  ['easy', 'fast', 'works', 'speed', 'runs', 'nice', 'look', 'awesome', 'value', 'faster', 'amazing', 'built', 'ease', 'display', 'excellent', 'easily', 'feature', 'ilife', 'feel', 'free', 'itunes']\n","Neutral lexicon:  ['photo', 'editing', 'movie', 'pages', 'music', 'keynote', 'numbers', 'nnbrrgb', 'school', 'extended', 'games', 'took', 'booth', 'management', 'email', 'doing', 'core', 'garageband', 'home', 'users', 'wanted', 'disk', 'called', 'server', 'enterprise', 'seconds', 'processing', 'dual', 'premium', 'firefox', 'save', 'monitor', 'compatible', 'difference', 'inside', 'safari', 'professional', 'youre', 'phone', 'finally', 'told', 'dreamweaver', 'messenger', 'spreadsheets', 'final', 'allows', 'photoshop', 'looked', 'standard', 'uses', 'store', 'check', 'sata', 'similar', 'outside', 'depot', 'application', 'motherboard', 'jack', 'constantly', 'thru', 'included', 'yourself', 'boot', 'backup', 'post', 'checking', 'paralles', 'virtual', 'complaints', 'show', 'casing', 'firewire', 'upgraded', 'various', 'imovie', 'under', 'hinge', 'intel', 'paid', 'getting', 'unit', 'stick', 'must', 'temperatures', 'camp', 'site', 'nnbrrxnnbrrgb', 'lets', 'controller', 'creative', 'internal', 'unplug', 'classroom', 'terms', 'itll', 'reload', 'speedy', 'bootcamp', 'actual', 'installing', 'sonic', 'stage', 'supposedly', 'enabled', 'docking', 'option', 'options', 'three', 'week', 'presentations', 'playing', 'machines', 'deal', 'protection', 'talk']\n"]}]},{"cell_type":"code","source":["#Adversarial dataset\n","#Modify input train dataset\n","x_original_opinions, x_adversarial_ABAA, x_train, x_aspects_, x_polaridad_, ss_, pr_, advexamples_, dataset_modified_ = AdversarialExamples(negative_lexicon, positive_lexicon, neutral_lexicon, x_train, a_train, p_train, 0.4)\n","\n","\n","print(\"Semantic similarity: \", ss_)\n","print(\"Perturbation ratio: \", pr_)\n","print(\"Data set modified: \", dataset_modified_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tgU6J3nVGiPn","executionInfo":{"status":"ok","timestamp":1728075507018,"user_tz":360,"elapsed":161,"user":{"displayName":"Monserrat Vázquez Hernández","userId":"12458819110641506711"}},"outputId":"7632ac58-b5d1-473c-9753-937d0ad014d3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Semantic similarity:  0.988\n","Perturbation ratio:  13.454\n","Data set modified:  20.408\n"]}]},{"cell_type":"code","source":["for i in range(len(x_adversarial_ABAA)):\n","  print(\"Opinion: \", x_original_opinions[i])\n","  print(\"Adversarial: \", x_adversarial_ABAA[i])\n","  print(\"Similarity: \", cosine_distance(VectorOpinion(x_original_opinions[i]),VectorOpinion(x_adversarial_ABAA[i])))\n","  print(\"-------------------------------\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-h89lVdl0R4f","executionInfo":{"status":"ok","timestamp":1728084293723,"user_tz":360,"elapsed":195,"user":{"displayName":"Monserrat Vázquez Hernández","userId":"12458819110641506711"}},"outputId":"567eeb56-b0a1-4b3c-c50f-61fcaac0c0a7"},"execution_count":176,"outputs":[{"output_type":"stream","name":"stdout","text":["Opinion:  build quality performance everything sub par would expected apple \n","Adversarial:  build quality performance everything sub par would expect apple \n","Similarity:  0.9930683245793069\n","-------------------------------\n","Opinion:  build quality performance everything sub par would expected apple \n","Adversarial:  build quality performance everything sub par would expect apple \n","Similarity:  0.9930683245793069\n","-------------------------------\n","Opinion:  boots fast runs great \n","Adversarial:  boots quick runs great \n","Similarity:  0.9646042706324885\n","-------------------------------\n","Opinion:  call tech support standard email form fax back us \n","Adversarial:  call tech support stock e-mail form fax back us \n","Similarity:  0.9861634479549136\n","-------------------------------\n","Opinion:  see macbook pro different may huge price tag comes full software would actually need free future updates \n","Adversarial:  see macbook pro different may huge price tag comes full software would actually need release future updates \n","Similarity:  0.9967644111384778\n","-------------------------------\n","Opinion:  see macbook pro different may huge price tag comes full software would actually need free future updates \n","Adversarial:  see macbook pro different may huge price tag comes full software would actually need release future updates \n","Similarity:  0.9967644111384778\n","-------------------------------\n","Opinion:  macbook arrived nice twin packing sealed box functions works great \n","Adversarial:  macbook arrived decent twin packing sealed box functions work great \n","Similarity:  0.9857333036746403\n","-------------------------------\n","Opinion:  macbook arrived nice twin packing sealed box functions works great \n","Adversarial:  macbook arrived nice twin packing sealed box functions work great \n","Similarity:  0.9935256470433257\n","-------------------------------\n","Opinion:  good speed plenty hard drive space \n","Adversarial:  good race plenty hard drive space \n","Similarity:  0.9769774492466551\n","-------------------------------\n","Opinion:  macbook notebooks quickly die short battery life well many background programs run without user's knowlede \n","Adversarial:  macbook notebooks quickly die little battery life well many background programs run without user's knowlede \n","Similarity:  0.9933738261131307\n","-------------------------------\n"]}]}]}